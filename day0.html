
<html>
<head>
<title>Data IAP Day 1</title>
<link rel="stylesheet" type="text/css" href="../clearness.css"/>
</head>
<body>
<h1>Syllabus and Setup</h1>
<p>Welcome!</p>
<p>This class is an introduction to data cleaning, analysis and
visualization.  We will walk you through as we analyze real world
datasets.  Each day, we will spend the first 30 minutes introducing
the day's concepts, and the rest of the class will be exercises.  We
have written a daily walkthrough that you will read and program
through in class, and we will be available to help.</p>
<p>This is our first time teaching this course, and we'll be learning as
much as you.  Don't hesitate to ask us to change something or improve
on something.  We'll be grateful.</p>
<h2>Prereqs</h2>
<p>We assume you have a working knowledge of python (6.01) and are
willing to write code.  Most of the code you interact with will come
with an example that you can modify.  Hopefully little specialized
code will be generated except for programs you're inspired to write!</p>
<h2>What we will teach</h2>
<p>We will teach the basics of data analysis through concrete examples.
All of your programming will be written in python.  The schedule is as follows:</p>
<ul>
<li>
<p>Day 0 (today): setup</p>
</li>
<li>
<p>Day 1: An end-to-end example getting you from a
  dataset found online to several plots of campaign contributions.</p>
</li>
<li>
<p>Day 2: Lots of visualization examples, and practice going from data
  to chart.</p>
</li>
<li>
<p>Day 3: Statistics basics, including T-Tests, Linear Regression, and
  statistical significance.  We'll use campaign finance and per-county
  health rankings.</p>
</li>
<li>
<p>Day 4: Text processing on a large text corpus (the Enron email
  dataset) using tf-idf and cosine similarity.</p>
</li>
<li>
<p>Day 5: Scaling up to process large datasets using Hadoop/MapReduce
  on a larger copy of the Enron dataset.</p>
</li>
<li>
<p>Day 6: You tell us!  Get into groups or work on your own to analyze
  a dataset of your choosing, and tell us a story!</p>
</li>
</ul>
<h2>What we will not teach</h2>
<ul>
<li>
<p><em>R</em>.  R is a wonderful data analysis, statistics, and plotting
framework.  We will not be using it because we can achieve all of our
objectives in Python, and more MIT undergraduates know Python.</p>
</li>
<li>
<p>Visualization using browser technology (canvas, svg, d3, etc) or in
  non python languages (<a href="http://processing.org/">Processing</a>.  These
  tools are very interesting, and lots of visualizations on the web
  use these tools (e.g., <a href="http://open.blogs.nytimes.com/2008/10/27/the-new-york-times-data-visualization-lab/">nytimes
  visualizations</a>),
  however they are out of the scope of this class.  We'll teach you
  how to visualize data in static charts.  If this is an area of
  interest for you, the next step will be to build interactive
  visualizations that the world can explore, and we can point you in
  the right direction with these.</p>
</li>
</ul>
<h2>Programming Environment (Important!)</h2>
<p>Before the class, please set up the environment.  You will need to install some software, packages, and download some datasets to get started.</p>
<p>We assume that you are developing in a unix-like environment and are
familiar with the common commands (e.g., less, man).  If you are a windows user, we
assume you are using cygwin but are on your own.</p>
<h2>Tools and Libraries</h2>
<p>In this class, you will need to install a number of tools.  The major
ones are:</p>
<ul>
<li><a href="http://www.python.org/getit/releases/2.7/">python 2.7</a><ul>
<li>Python is
  usually installed in Mac OSX and major unix distributions.  Type
  <code>python --version</code> to make sure it is the right version</li>
</ul>
</li>
<li><a href="http://pypi.python.org/pypi/setuptools">easy_install</a> <ul>
<li>python package manager.</li>
</ul>
</li>
<li><a href="http://pypi.python.org/pypi/pip#downloads">pip</a><ul>
<li>Makes installing python packages really easy.  Requires easy_install.</li>
<li>Either install it by typing <code>sudo easy_install pip</code> or download the tar.gz file at the link above, untar it, go into the newly created directory, and type <code>sudo python setup.py install</code>.</li>
</ul>
</li>
<li><a href="http://git-scm.com/">git</a><ul>
<li>git is a version control system.  Using it, you can check out our code and examples.</li>
<li>If everything is working, check the dataiap sourcecode into a
  directory called <code>dataiap</code> using <code>git clone
  git://github.com/dataiap/dataiap.git dataiap</code></li>
<li>We'll be updating the repository periodically.  To get the latest copy, go to the <code>dataiap</code> directory and type <code>git pull</code>.</li>
</ul>
</li>
</ul>
<p>We will also require a number of python modules:</p>
<ul>
<li><a href="http://sourceforge.net/projects/numpy/files/NumPy/1.6.1/">numpy 1.6.x</a>: numerical processing module.<ul>
<li>PIP users can type <code>sudo pip install numpy</code></li>
</ul>
</li>
<li>
<p><a href="http://sourceforge.net/projects/scipy/files/scipy/0.10.0/">scipy 0.10</a>: scientific computing module.</p>
<ul>
<li>Ubuntu users can type <code>sudo apt-get install python-scipy</code></li>
<li>PIP users can type <code>sudo pip install scipy</code></li>
<li>Even if PIP works, at least on MacOS you might have to <a href="https://www.scipy.org/Installing_SciPy/Mac_OS_X">install Fortran</a>.  We strongly recommend reading and following the <a href="https://www.scipy.org/Installing_SciPy/Mac_OS_X">installation instructions</a>.</li>
<li>Unfortunately, scipy installation might not work from PIP, and you may have to <a href="https://scipy.org/Installing_SciPy/Mac_OS_X">compile it from source</a> (see "Obtaining and Building NumPy and SciPy").  Try something akin to<ul>
<li><code>git clone https://github.com/scipy/scipy.git</code></li>
<li><code>cd scipy</code></li>
<li><code>python setup.py build</code></li>
<li><code>python setup.py install</code></li>
</ul>
</li>
</ul>
</li>
<li>
<p><a href="http://sourceforge.net/projects/matplotlib/files/matplotlib/matplotlib-1.1.0/">matplotlib 1.1.0</a></p>
<ul>
<li>PIP users can type <code>sudo pip install matplotlib</code></li>
<li>Note: If compiling from source, matplot lib requires a number of other libraries: 
(<a href="http://www.libpng.org/pub/png/libpng.html">libpng</a>, <a href="http://download.savannah.gnu.org/releases/freetype/">freetype 2</a>)</li>
<li>Some MacOS users might run into issues and should just download <a href="http://sourceforge.net/projects/matplotlib/files/matplotlib/matplotlib-1.1.0/matplotlib-1.1.0-py2.7-python.org-macosx10.3.dmg/download">the binary</a>.</li>
</ul>
</li>
<li>
<p><a href="http://labix.org/python-dateutil#head-2f49784d6b27bae60cde1cff6a535663cf87497b">dateutil</a></p>
<ul>
<li>PIP users can type <code>sudo pip install python-dateutil</code></li>
</ul>
</li>
<li><a href="http://pyparsing.wikispaces.com/Download+and+Installation">pyparsing</a><ul>
<li>PIP users can type <code>sudo pip install pyparsing</code></li>
</ul>
</li>
<li><a href="https://github.com/yelp/mrjob">mrjob</a>:  This is a MapReduce package that we will use it in day 5.<ul>
<li>PIP users can type <code>sudo pip install mrjob</code></li>
<li>If compiling from source, it requires <a href="http://code.google.com/p/boto/downloads/list">boto</a> (try <code>sudo pip install boto</code>).</li>
</ul>
</li>
</ul>
<h2><code>dataiap/</code> Directory Structure</h2>
<p>The repository contains the contents of the full course.  We will be using</p>
<ul>
<li><code>dayX/</code>: files containing the lecture for day X</li>
<li><code>datasets/</code>: the datasets we will be using should live here</li>
<li><code>resources/</code>: contains python scripts that you will eventually run<ul>
<li><code>util/</code>: contains python modules we have written that you will use in this course.</li>
<li><code>inst/</code>: instructor python files.  Used to setup and test the labs.  Please don't view during the course.</li>
</ul>
</li>
</ul>
<h2>Datasets</h2>
<p>We will be working with several datasets in this course.  Most of them have been added to the git repository.</p>
<!--We have packaged and uploaded several of them to [http://web.mit.edu/~eugenewu/Public/datasets.zip](http://web.mit.edu/~eugenewu/Public/datasets.zip).  Please download and uncompress this into your `dataiap/` directory before class.-->

<p>The presidential contributions dataset is fairly large.  We will use it on the first day, so please download it from <a href="ftp://ftp.fec.gov/FEC/Presidential_Map/2008/P00000001/P00000001-ALL.zip">ftp://ftp.fec.gov/FEC/Presidential_Map/2008/P00000001/P00000001-ALL.zip</a>.</p>
<p>The datasets we will use are</p>
<ul>
<li><a href="ftp://ftp.fec.gov/FEC/Presidential_Map/2008/P00000001/P00000001-ALL.zip">2008 Presidential Campaign Contributions</a><ul>
<li>The linked file contains all of the 2008 campaign contributions to each presidential candidate.  You can look at the <a href="http://fec.gov/disclosurep/PDownload.do">2012 campaign</a> for various primary candidates as well, but we'll work with 2008 since it's complete.<br />
</li>
<li>unzip into <code>dataiap/datasets/pres_campaign/</code></li>
</ul>
</li>
<li><a href="http://www.countyhealthrankings.org/">2011 County Health Rankings</a><ul>
<li>The dataset contains per-county health and morbidity statistics.</li>
<li>The necessary data should already be uncompressed in
<code>dataiap/datasets/county_health_rankings/additional_measures_cleaned.csv</code><br />
<code>dataiap/datasets/county_health_rankings/ypll.csv</code><br />
</li>
</ul>
</li>
<li><a href="http://www.cs.cmu.edu/~enron/">The Enron email dataset</a><ul>
<li>This is the complete set of emails on the enron email server that was released during the scandal. Don't download the dataset as it's huge.  We have included subsets of the datasets in the git repository.<ul>
<li><code>dataiap/datasets/emails/kenneth.zip</code> contains a subset of Kenneth Lay's emails that you will analyze in day 4.</li>
<li><code>dataiap/datasets/emails/kenneth_json.zip</code> contains a JSON-encoded subset of Kenneth Lay's emails that you will analyze in day 5.</li>
</ul>
</li>
<li>We will upload a JSON encoded version of the full dataset to amazon's S3.<br />
</li>
</ul>
</li>
</ul>
</body>
</html>
